{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-28T00:58:47.332802Z",
     "iopub.status.busy": "2025-11-28T00:58:47.332494Z",
     "iopub.status.idle": "2025-11-28T00:58:48.086040Z",
     "shell.execute_reply": "2025-11-28T00:58:48.085090Z",
     "shell.execute_reply.started": "2025-11-28T00:58:47.332769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Profiling_gender_dialect'...\n",
      "remote: Enumerating objects: 66, done.\u001b[K\n",
      "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "remote: Total 66 (delta 30), reused 57 (delta 21), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (66/66), 55.35 KiB | 5.03 MiB/s, done.\n",
      "Resolving deltas: 100% (30/30), done.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Vietnamese Speaker Profiling - Kaggle Training\n",
    "# ============================================================\n",
    "!git clone https://github.com/VuThanhLam124/Profiling_gender_dialect.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T00:59:58.389156Z",
     "iopub.status.busy": "2025-11-28T00:59:58.388813Z",
     "iopub.status.idle": "2025-11-28T00:59:58.395947Z",
     "shell.execute_reply": "2025-11-28T00:59:58.395309Z",
     "shell.execute_reply.started": "2025-11-28T00:59:58.389106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Profiling_gender_dialect\n"
     ]
    }
   ],
   "source": [
    "cd Profiling_gender_dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py    eval.py      infer.py    prepare_data.py  requirements.txt\n",
      "\u001b[0m\u001b[01;34mconfigs\u001b[0m/  finetune.py  \u001b[01;34mnotebooks\u001b[0m/  README.md        \u001b[01;34msrc\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T00:59:59.248473Z",
     "iopub.status.busy": "2025-11-28T00:59:59.247861Z",
     "iopub.status.idle": "2025-11-28T00:59:59.369711Z",
     "shell.execute_reply": "2025-11-28T00:59:59.368879Z",
     "shell.execute_reply.started": "2025-11-28T00:59:59.248444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.53.3)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.13.1)\n",
      "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.2.3)\n",
      "Collecting scikit-learn>=1.3.0 (from -r requirements.txt (line 8))\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting audiomentations==0.35.0 (from -r requirements.txt (line 9))\n",
      "  Downloading audiomentations-0.35.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.5.3)\n",
      "Requirement already satisfied: accelerate>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.9.0)\n",
      "Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (5.38.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
      "Collecting mlflow>=2.10.0 (from -r requirements.txt (line 15))\n",
      "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting librosa>=0.10.0 (from -r requirements.txt (line 4))\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.35.0->-r requirements.txt (line 9)) (1.15.3)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.35.0->-r requirements.txt (line 9)) (0.5.0.post1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 3)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 3)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 3)) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 3)) (0.21.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (0.60.0)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->-r requirements.txt (line 4)) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->-r requirements.txt (line 6)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->-r requirements.txt (line 6)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->-r requirements.txt (line 6)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->-r requirements.txt (line 6)) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->-r requirements.txt (line 6)) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->-r requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.3.0->-r requirements.txt (line 10)) (4.9.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.0->-r requirements.txt (line 12)) (7.1.3)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (4.11.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (1.11.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (3.11.0)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (11.3.0)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio>=4.0.0->-r requirements.txt (line 13))\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.12.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.47.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 13)) (0.35.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio>=4.0.0->-r requirements.txt (line 13)) (15.0.1)\n",
      "Collecting mlflow-skinny==3.6.0 (from mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.6.0 (from mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (1.17.1)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (46.0.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (7.1.0)\n",
      "Collecting graphene<4 (from mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (3.7.2)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (19.0.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.10.0->-r requirements.txt (line 15)) (2.0.41)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (8.3.0)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (6.33.0)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.2.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (0.5.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.3.10)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 13)) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->-r requirements.txt (line 5)) (2.23)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (2.5.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (3.1.3)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 13)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 13)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 13)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.30.0->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow>=2.10.0->-r requirements.txt (line 15)) (3.0.9)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.10.0->-r requirements.txt (line 4)) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio>=4.0.0->-r requirements.txt (line 13)) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio>=4.0.0->-r requirements.txt (line 13))\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio>=4.0.0->-r requirements.txt (line 13)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (3.2.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 13)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 13)) (14.2.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->-r requirements.txt (line 6)) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->-r requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->-r requirements.txt (line 6)) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0->-r requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (2.38.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (3.23.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0->-r requirements.txt (line 6)) (2024.2.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (0.58b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 13)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 13)) (2.19.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (5.0.2)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (4.9.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.10.0->-r requirements.txt (line 15)) (0.6.1)\n",
      "Downloading audiomentations-0.35.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huey-2.5.4-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: huey, pydantic-core, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gunicorn, graphql-core, cachetools, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, graphql-relay, nvidia-cusolver-cu12, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, scikit-learn, librosa, mlflow, audiomentations\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.41.5\n",
      "    Uninstalling pydantic_core-2.41.5:\n",
      "      Successfully uninstalled pydantic_core-2.41.5\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 6.2.1\n",
      "    Uninstalling cachetools-6.2.1:\n",
      "      Successfully uninstalled cachetools-6.2.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.12.4\n",
      "    Uninstalling pydantic-2.12.4:\n",
      "      Successfully uninstalled pydantic-2.12.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.11.0\n",
      "    Uninstalling librosa-0.11.0:\n",
      "      Successfully uninstalled librosa-0.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-CORS-6.0.1 audiomentations-0.35.0 cachetools-5.5.2 databricks-sdk-0.73.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.4 librosa-0.10.2.post1 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-2.11.10 pydantic-core-2.33.2 scikit-learn-1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:00:00.060672Z",
     "iopub.status.busy": "2025-11-28T01:00:00.059900Z",
     "iopub.status.idle": "2025-11-28T01:00:00.066428Z",
     "shell.execute_reply": "2025-11-28T01:00:00.065525Z",
     "shell.execute_reply.started": "2025-11-28T01:00:00.060640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "  trainset/\n",
      "    - ViSpeech_00569.mp3\n",
      "    - ViSpeech_04453.mp3\n",
      "    - ViSpeech_03028.mp3\n",
      "  metadata/\n",
      "    - trainset.csv\n",
      "    - clean_testset.csv\n",
      "    - noisy_testset.csv\n",
      "  noisy_testset/\n",
      "    - ViSpeech_10402.mp3\n",
      "    - ViSpeech_10495.mp3\n",
      "    - ViSpeech_10020.mp3\n",
      "  clean_testset/\n",
      "    - ViSpeech_09610.mp3\n",
      "    - ViSpeech_09244.mp3\n",
      "    - ViSpeech_09148.mp3\n",
      "\n",
      "Metadata columns:\n",
      "  Columns: ['audio_name', 'dialect', 'gender', 'speaker']\n",
      "  Samples: 8166\n",
      "\n",
      "First 3 rows:\n",
      "           audio_name  dialect gender  speaker\n",
      "0  ViSpeech_00001.mp3  Central   Male  SPK0001\n",
      "1  ViSpeech_00002.mp3  Central   Male  SPK0001\n",
      "2  ViSpeech_00003.mp3  Central   Male  SPK0001\n"
     ]
    }
   ],
   "source": [
    "# Check dataset structure\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "VISPEECH_ROOT = \"/kaggle/input/vispeech\"\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "for item in os.listdir(VISPEECH_ROOT):\n",
    "    item_path = os.path.join(VISPEECH_ROOT, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        print(f\"  {item}/\")\n",
    "        for subitem in os.listdir(item_path)[:3]:\n",
    "            print(f\"    - {subitem}\")\n",
    "    else:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "# Check metadata format\n",
    "print(\"\\nMetadata columns:\")\n",
    "meta_path = os.path.join(VISPEECH_ROOT, \"metadata/trainset.csv\")\n",
    "df = pd.read_csv(meta_path)\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "print(f\"  Samples: {len(df)}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(df.head(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:00:03.136980Z",
     "iopub.status.busy": "2025-11-28T01:00:03.136707Z",
     "iopub.status.idle": "2025-11-28T01:00:03.258228Z",
     "shell.execute_reply": "2025-11-28T01:00:03.257215Z",
     "shell.execute_reply.started": "2025-11-28T01:00:03.136960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file created: configs/finetune.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create Kaggle-specific config\n",
    "config_content = \"\"\"\n",
    "# Finetune Configuration for Kaggle\n",
    "# Architecture: WavLM + Attentive Pooling + LayerNorm\n",
    "\n",
    "# Model\n",
    "model:\n",
    "  name: \"microsoft/wavlm-base-plus\"\n",
    "  hidden_size: 768\n",
    "  num_genders: 2\n",
    "  num_dialects: 3\n",
    "  dropout: 0.1\n",
    "  head_hidden_dim: 256\n",
    "\n",
    "# Training\n",
    "training:\n",
    "  batch_size: 32\n",
    "  learning_rate: 5e-5\n",
    "  num_epochs: 15\n",
    "  warmup_ratio: 0.125\n",
    "  weight_decay: 0.0125\n",
    "  gradient_clip: 1.0\n",
    "  lr_scheduler: \"linear\"\n",
    "  fp16: true\n",
    "  dataloader_num_workers: 2\n",
    "\n",
    "# Loss\n",
    "loss:\n",
    "  dialect_weight: 3.0\n",
    "\n",
    "# MLflow Configuration\n",
    "mlflow:\n",
    "  enabled: false  # Disable on Kaggle\n",
    "\n",
    "# Dataset paths - Kaggle specific\n",
    "data:\n",
    "  # Raw dataset paths (for prepare_data.py)\n",
    "  vispeech_root: \"/kaggle/input/vispeech\"\n",
    "  train_meta: \"/kaggle/input/vispeech/metadata/trainset.csv\"\n",
    "  train_audio: \"/kaggle/input/vispeech/trainset\"\n",
    "  clean_test_meta: \"/kaggle/input/vispeech/metadata/clean_testset.csv\"\n",
    "  clean_test_audio: \"/kaggle/input/vispeech/clean_testset\"\n",
    "  noisy_test_meta: \"/kaggle/input/vispeech/metadata/noisy_testset.csv\"\n",
    "  noisy_test_audio: \"/kaggle/input/vispeech/noisy_testset\"\n",
    "  val_split: 0.15\n",
    "  \n",
    "  # Extracted features paths (for finetune.py)\n",
    "  train_dir: \"/kaggle/working/datasets/ViSpeech/train\"\n",
    "  val_dir: \"/kaggle/working/datasets/ViSpeech/val\"\n",
    "\n",
    "# Audio Processing\n",
    "audio:\n",
    "  sampling_rate: 16000\n",
    "  max_duration: 5\n",
    "\n",
    "# Output\n",
    "output:\n",
    "  dir: \"/kaggle/working/output\"\n",
    "  save_total_limit: 2\n",
    "  metric_for_best_model: \"dialect_acc\"\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping:\n",
    "  patience: 3\n",
    "  threshold: 0.0025\n",
    "\n",
    "# Label Mappings\n",
    "labels:\n",
    "  gender:\n",
    "    Male: 0\n",
    "    Female: 1\n",
    "  dialect:\n",
    "    North: 0\n",
    "    Central: 1\n",
    "    South: 2\n",
    "\n",
    "# Reproducibility\n",
    "seed: 42\n",
    "\"\"\"\n",
    "\n",
    "with open(\"configs/finetune.yaml\", \"w\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"Config file created: configs/finetune.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 01:24:37.415751: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764293077.604606     209 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764293077.604606     209 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764293077.659527     209 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1764293077.659527     209 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "2025-11-28 01:24:57 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:24:57 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:24:57 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:24:57 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:24:57 | INFO | Split: train\n",
      "INFO:speaker_profiling:Split: train\n",
      "2025-11-28 01:24:57 | INFO | Output: /kaggle/working/datasets/ViSpeech/train\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/train\n",
      "2025-11-28 01:24:57 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:24:57 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:24:57 | INFO | ViSpeech dataset - Split: train\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: train\n",
      "2025-11-28 01:24:57 | INFO |   Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:24:57 | INFO |   Audio dir: /kaggle/input/vispeech/trainset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/trainset\n",
      "2025-11-28 01:24:57 | INFO |   Val split ratio: 0.15\n",
      "INFO:speaker_profiling:  Val split ratio: 0.15\n",
      "2025-11-28 01:24:57 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:24:57 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:24:57 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:24:57 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:24:57 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:24:57 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:24:57 | INFO | Split: train\n",
      "INFO:speaker_profiling:Split: train\n",
      "2025-11-28 01:24:57 | INFO | Output: /kaggle/working/datasets/ViSpeech/train\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/train\n",
      "2025-11-28 01:24:57 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:24:57 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:24:57 | INFO | ViSpeech dataset - Split: train\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: train\n",
      "2025-11-28 01:24:57 | INFO |   Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:24:57 | INFO |   Audio dir: /kaggle/input/vispeech/trainset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/trainset\n",
      "2025-11-28 01:24:57 | INFO |   Val split ratio: 0.15\n",
      "INFO:speaker_profiling:  Val split ratio: 0.15\n",
      "2025-11-28 01:24:57 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:24:57 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "preprocessor_config.json: 100%|████████████████| 215/215 [00:00<00:00, 1.39MB/s]\n",
      "preprocessor_config.json: 100%|████████████████| 215/215 [00:00<00:00, 1.39MB/s]\n",
      "config.json: 2.23kB [00:00, 9.97MB/s]\n",
      "config.json: 2.23kB [00:00, 9.97MB/s]\n",
      "pytorch_model.bin: 100%|██████████████████████| 378M/378M [00:01<00:00, 218MB/s]\n",
      "pytorch_model.bin: 100%|██████████████████████| 378M/378M [00:01<00:00, 218MB/s]\n",
      "2025-11-28 01:25:00 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:25:00 | INFO | Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:25:00 | INFO | Total speakers: 310\n",
      "INFO:speaker_profiling:Total speakers: 310\n",
      "2025-11-28 01:25:00 | INFO | Train speakers: 263, Val speakers: 47\n",
      "INFO:speaker_profiling:Train speakers: 263, Val speakers: 47\n",
      "2025-11-28 01:25:00 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:25:00 | INFO | Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:25:00 | INFO | Total speakers: 310\n",
      "INFO:speaker_profiling:Total speakers: 310\n",
      "2025-11-28 01:25:00 | INFO | Train speakers: 263, Val speakers: 47\n",
      "INFO:speaker_profiling:Train speakers: 263, Val speakers: 47\n",
      "2025-11-28 01:25:00 | INFO | After split - train: 7137 samples\n",
      "INFO:speaker_profiling:After split - train: 7137 samples\n",
      "2025-11-28 01:25:00 | INFO | Extracting features for 7137 samples...\n",
      "INFO:speaker_profiling:Extracting features for 7137 samples...\n",
      "Extracting features:   0%|                             | 0/7137 [00:00<?, ?it/s]2025-11-28 01:25:00 | INFO | After split - train: 7137 samples\n",
      "INFO:speaker_profiling:After split - train: 7137 samples\n",
      "2025-11-28 01:25:00 | INFO | Extracting features for 7137 samples...\n",
      "INFO:speaker_profiling:Extracting features for 7137 samples...\n",
      "Extracting features:   0%|                             | 0/7137 [00:00<?, ?it/s]\n",
      "model.safetensors:   0%|                             | 0.00/378M [00:00<?, ?B/s]\u001b[A\n",
      "model.safetensors:   0%|                             | 0.00/378M [00:00<?, ?B/s]\u001b[A\n",
      "model.safetensors:  11%|██▏                 | 42.2M/378M [00:01<00:08, 39.8MB/s]\u001b[A\n",
      "model.safetensors:  11%|██▏                 | 42.2M/378M [00:01<00:08, 39.8MB/s]\u001b[A\n",
      "model.safetensors:  29%|██████▎               | 109M/378M [00:01<00:02, 106MB/s]\u001b[A\n",
      "model.safetensors:  29%|██████▎               | 109M/378M [00:01<00:02, 106MB/s]\u001b[A\n",
      "model.safetensors:  47%|██████████▎           | 176M/378M [00:01<00:01, 180MB/s]\u001b[A\n",
      "model.safetensors:  47%|██████████▎           | 176M/378M [00:01<00:01, 180MB/s]\u001b[A\n",
      "model.safetensors:  82%|██████████████████    | 310M/378M [00:01<00:00, 349MB/s]\u001b[A\n",
      "model.safetensors: 100%|██████████████████████| 378M/378M [00:01<00:00, 247MB/s]\u001b[A\n",
      "model.safetensors: 100%|██████████████████████| 378M/378M [00:01<00:00, 247MB/s]\n",
      "Extracting features: 100%|██████████████████| 7137/7137 [06:08<00:00, 19.39it/s]\n",
      "2025-11-28 01:31:09 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "2025-11-28 01:31:09 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/train/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/train/stats.json\n",
      "2025-11-28 01:31:09 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:31:09 | INFO |   Success: 7137/7137\n",
      "INFO:speaker_profiling:  Success: 7137/7137\n",
      "2025-11-28 01:31:09 | INFO |   Failed: 0/7137\n",
      "INFO:speaker_profiling:  Failed: 0/7137\n",
      "Extracting features: 100%|██████████████████| 7137/7137 [06:08<00:00, 19.39it/s]\n",
      "2025-11-28 01:31:09 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "2025-11-28 01:31:09 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/train/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/train/stats.json\n",
      "2025-11-28 01:31:09 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:31:09 | INFO |   Success: 7137/7137\n",
      "INFO:speaker_profiling:  Success: 7137/7137\n",
      "2025-11-28 01:31:09 | INFO |   Failed: 0/7137\n",
      "INFO:speaker_profiling:  Failed: 0/7137\n",
      "2025-11-28 01:31:09 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:31:09 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:31:09 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:31:09 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:31:09 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:31:09 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/train\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/train\"  # for training set\n",
      "2025-11-28 01:31:09 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m2025-11-28 01:31:09 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:31:09 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:31:09 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:31:09 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:31:09 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:31:09 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/train\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/train\"  # for training set\n",
      "2025-11-28 01:31:09 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Extract training features (~85% of trainset)\n",
    "!python prepare_data.py \\\n",
    "    --dataset vispeech \\\n",
    "    --config configs/finetune.yaml \\\n",
    "    --output_dir /kaggle/working/datasets/ViSpeech/train \\\n",
    "    --split train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 01:33:08.574144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764293588.601269     250 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764293588.608780     250 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764293588.601269     250 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764293588.608780     250 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "2025-11-28 01:33:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:33:15 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:33:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:33:15 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:33:15 | INFO | Split: val\n",
      "INFO:speaker_profiling:Split: val\n",
      "2025-11-28 01:33:15 | INFO | Output: /kaggle/working/datasets/ViSpeech/val\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/val\n",
      "2025-11-28 01:33:15 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:33:15 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:33:15 | INFO | ViSpeech dataset - Split: val\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: val\n",
      "2025-11-28 01:33:15 | INFO |   Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:33:15 | INFO |   Audio dir: /kaggle/input/vispeech/trainset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/trainset\n",
      "2025-11-28 01:33:15 | INFO |   Val split ratio: 0.15\n",
      "INFO:speaker_profiling:  Val split ratio: 0.15\n",
      "2025-11-28 01:33:15 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:33:15 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:33:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:33:15 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:33:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:33:15 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:33:15 | INFO | Split: val\n",
      "INFO:speaker_profiling:Split: val\n",
      "2025-11-28 01:33:15 | INFO | Output: /kaggle/working/datasets/ViSpeech/val\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/val\n",
      "2025-11-28 01:33:15 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:33:15 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:33:15 | INFO | ViSpeech dataset - Split: val\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: val\n",
      "2025-11-28 01:33:15 | INFO |   Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:33:15 | INFO |   Audio dir: /kaggle/input/vispeech/trainset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/trainset\n",
      "2025-11-28 01:33:15 | INFO |   Val split ratio: 0.15\n",
      "INFO:speaker_profiling:  Val split ratio: 0.15\n",
      "2025-11-28 01:33:15 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:33:15 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:33:16 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:33:16 | INFO | Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:33:16 | INFO | Total speakers: 310\n",
      "INFO:speaker_profiling:Total speakers: 310\n",
      "2025-11-28 01:33:16 | INFO | Train speakers: 263, Val speakers: 47\n",
      "INFO:speaker_profiling:Train speakers: 263, Val speakers: 47\n",
      "2025-11-28 01:33:16 | INFO | After split - val: 1029 samples\n",
      "INFO:speaker_profiling:After split - val: 1029 samples\n",
      "2025-11-28 01:33:16 | INFO | Extracting features for 1029 samples...\n",
      "INFO:speaker_profiling:Extracting features for 1029 samples...\n",
      "Extracting features:   0%|                             | 0/1029 [00:00<?, ?it/s]2025-11-28 01:33:16 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:33:16 | INFO | Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "INFO:speaker_profiling:Loaded 8166 total samples from /kaggle/input/vispeech/metadata/trainset.csv\n",
      "2025-11-28 01:33:16 | INFO | Total speakers: 310\n",
      "INFO:speaker_profiling:Total speakers: 310\n",
      "2025-11-28 01:33:16 | INFO | Train speakers: 263, Val speakers: 47\n",
      "INFO:speaker_profiling:Train speakers: 263, Val speakers: 47\n",
      "2025-11-28 01:33:16 | INFO | After split - val: 1029 samples\n",
      "INFO:speaker_profiling:After split - val: 1029 samples\n",
      "2025-11-28 01:33:16 | INFO | Extracting features for 1029 samples...\n",
      "INFO:speaker_profiling:Extracting features for 1029 samples...\n",
      "Extracting features: 100%|██████████████████| 1029/1029 [00:48<00:00, 21.43it/s]\n",
      "Extracting features: 100%|██████████████████| 1029/1029 [00:48<00:00, 21.43it/s]\n",
      "2025-11-28 01:34:04 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "2025-11-28 01:34:04 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/val/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/val/stats.json\n",
      "2025-11-28 01:34:04 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:34:04 | INFO |   Success: 1029/1029\n",
      "INFO:speaker_profiling:  Success: 1029/1029\n",
      "2025-11-28 01:34:04 | INFO |   Failed: 0/1029\n",
      "INFO:speaker_profiling:  Failed: 0/1029\n",
      "2025-11-28 01:34:04 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:34:04 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:34:04 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:34:04 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:34:04 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:34:04 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/val\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/val\"  # for training set\n",
      "2025-11-28 01:34:04 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m2025-11-28 01:34:04 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "2025-11-28 01:34:04 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/val/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/val/stats.json\n",
      "2025-11-28 01:34:04 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:34:04 | INFO |   Success: 1029/1029\n",
      "INFO:speaker_profiling:  Success: 1029/1029\n",
      "2025-11-28 01:34:04 | INFO |   Failed: 0/1029\n",
      "INFO:speaker_profiling:  Failed: 0/1029\n",
      "2025-11-28 01:34:04 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:34:04 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:34:04 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:34:04 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:34:04 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:34:04 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/val\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/val\"  # for training set\n",
      "2025-11-28 01:34:04 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Extract validation features (~15% of trainset)\n",
    "!python prepare_data.py \\\n",
    "    --dataset vispeech \\\n",
    "    --config configs/finetune.yaml \\\n",
    "    --output_dir /kaggle/working/datasets/ViSpeech/val \\\n",
    "    --split val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features:\n",
      "  train: 7137 files\n",
      "  val: 1029 files\n"
     ]
    }
   ],
   "source": [
    "# Verify extracted features\n",
    "import os\n",
    "print(\"Extracted features:\")\n",
    "for split in ['train', 'val']:\n",
    "    path = f\"/kaggle/working/datasets/ViSpeech/{split}\"\n",
    "    if os.path.exists(path):\n",
    "        features_dir = os.path.join(path, 'features')\n",
    "        n_files = len(os.listdir(features_dir)) if os.path.exists(features_dir) else 0\n",
    "        print(f\"  {split}: {n_files} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 01:38:04.914687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764293884.939605     276 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764293884.947971     276 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "E0000 00:00:1764293884.947971     276 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "2025-11-28 01:38:13 | INFO | ==================================================\n",
      "INFO:speaker_profiling:==================================================\n",
      "2025-11-28 01:38:13 | INFO | SPEAKER PROFILING TRAINING\n",
      "INFO:speaker_profiling:SPEAKER PROFILING TRAINING\n",
      "2025-11-28 01:38:13 | INFO | ==================================================\n",
      "INFO:speaker_profiling:==================================================\n",
      "2025-11-28 01:38:13 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:38:13 | INFO | Dataset: /kaggle/working/datasets/ViSpeech/train\n",
      "INFO:speaker_profiling:Dataset: /kaggle/working/datasets/ViSpeech/train\n",
      "2025-11-28 01:38:13 | INFO | Batch Size: 32\n",
      "INFO:speaker_profiling:Batch Size: 32\n",
      "2025-11-28 01:38:13 | INFO | Learning Rate: 5e-05\n",
      "INFO:speaker_profiling:Learning Rate: 5e-05\n",
      "2025-11-28 01:38:13 | INFO | Epochs: 15\n",
      "INFO:speaker_profiling:Epochs: 15\n",
      "2025-11-28 01:38:13 | INFO | --------------------------------------------------\n",
      "INFO:speaker_profiling:--------------------------------------------------\n",
      "2025-11-28 01:38:13 | INFO | Loading datasets...\n",
      "INFO:speaker_profiling:Loading datasets...\n",
      "2025-11-28 01:38:13 | INFO | Loaded 7137 samples from /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "INFO:speaker_profiling:Loaded 7137 samples from /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "2025-11-28 01:38:13 | INFO | Loaded 1029 samples from /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "INFO:speaker_profiling:Loaded 1029 samples from /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "2025-11-28 01:38:13 | INFO | Train: 7,137 samples\n",
      "INFO:speaker_profiling:Train: 7,137 samples\n",
      "2025-11-28 01:38:13 | INFO | Validation: 1,029 samples\n",
      "INFO:speaker_profiling:Validation: 1,029 samples\n",
      "2025-11-28 01:38:13 | INFO | Loading model...\n",
      "INFO:speaker_profiling:Loading model...\n",
      "2025-11-28 01:38:13 | INFO | ==================================================\n",
      "INFO:speaker_profiling:==================================================\n",
      "2025-11-28 01:38:13 | INFO | SPEAKER PROFILING TRAINING\n",
      "INFO:speaker_profiling:SPEAKER PROFILING TRAINING\n",
      "2025-11-28 01:38:13 | INFO | ==================================================\n",
      "INFO:speaker_profiling:==================================================\n",
      "2025-11-28 01:38:13 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:38:13 | INFO | Dataset: /kaggle/working/datasets/ViSpeech/train\n",
      "INFO:speaker_profiling:Dataset: /kaggle/working/datasets/ViSpeech/train\n",
      "2025-11-28 01:38:13 | INFO | Batch Size: 32\n",
      "INFO:speaker_profiling:Batch Size: 32\n",
      "2025-11-28 01:38:13 | INFO | Learning Rate: 5e-05\n",
      "INFO:speaker_profiling:Learning Rate: 5e-05\n",
      "2025-11-28 01:38:13 | INFO | Epochs: 15\n",
      "INFO:speaker_profiling:Epochs: 15\n",
      "2025-11-28 01:38:13 | INFO | --------------------------------------------------\n",
      "INFO:speaker_profiling:--------------------------------------------------\n",
      "2025-11-28 01:38:13 | INFO | Loading datasets...\n",
      "INFO:speaker_profiling:Loading datasets...\n",
      "2025-11-28 01:38:13 | INFO | Loaded 7137 samples from /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "INFO:speaker_profiling:Loaded 7137 samples from /kaggle/working/datasets/ViSpeech/train/metadata.csv\n",
      "2025-11-28 01:38:13 | INFO | Loaded 1029 samples from /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "INFO:speaker_profiling:Loaded 1029 samples from /kaggle/working/datasets/ViSpeech/val/metadata.csv\n",
      "2025-11-28 01:38:13 | INFO | Train: 7,137 samples\n",
      "INFO:speaker_profiling:Train: 7,137 samples\n",
      "2025-11-28 01:38:13 | INFO | Validation: 1,029 samples\n",
      "INFO:speaker_profiling:Validation: 1,029 samples\n",
      "2025-11-28 01:38:13 | INFO | Loading model...\n",
      "INFO:speaker_profiling:Loading model...\n",
      "2025-11-28 01:38:13 | INFO | ClassificationHeadModel initialized (hidden_size=768)\n",
      "INFO:speaker_profiling:ClassificationHeadModel initialized (hidden_size=768)\n",
      "2025-11-28 01:38:13 | INFO | Architecture: Attentive Pooling + LayerNorm + Classification Heads\n",
      "INFO:speaker_profiling:Architecture: Attentive Pooling + LayerNorm + Classification Heads\n",
      "2025-11-28 01:38:13 | INFO | Hidden size: 768\n",
      "INFO:speaker_profiling:Hidden size: 768\n",
      "2025-11-28 01:38:13 | INFO | Head hidden dim: 256\n",
      "INFO:speaker_profiling:Head hidden dim: 256\n",
      "2025-11-28 01:38:13 | INFO | Dropout: 0.1\n",
      "INFO:speaker_profiling:Dropout: 0.1\n",
      "2025-11-28 01:38:13 | INFO | Total parameters: 1,020,421\n",
      "INFO:speaker_profiling:Total parameters: 1,020,421\n",
      "2025-11-28 01:38:13 | INFO | Trainable parameters: 1,020,421\n",
      "INFO:speaker_profiling:Trainable parameters: 1,020,421\n",
      "2025-11-28 01:38:13 | INFO | ClassificationHeadModel initialized (hidden_size=768)\n",
      "INFO:speaker_profiling:ClassificationHeadModel initialized (hidden_size=768)\n",
      "2025-11-28 01:38:13 | INFO | Architecture: Attentive Pooling + LayerNorm + Classification Heads\n",
      "INFO:speaker_profiling:Architecture: Attentive Pooling + LayerNorm + Classification Heads\n",
      "2025-11-28 01:38:13 | INFO | Hidden size: 768\n",
      "INFO:speaker_profiling:Hidden size: 768\n",
      "2025-11-28 01:38:13 | INFO | Head hidden dim: 256\n",
      "INFO:speaker_profiling:Head hidden dim: 256\n",
      "2025-11-28 01:38:13 | INFO | Dropout: 0.1\n",
      "INFO:speaker_profiling:Dropout: 0.1\n",
      "2025-11-28 01:38:13 | INFO | Total parameters: 1,020,421\n",
      "INFO:speaker_profiling:Total parameters: 1,020,421\n",
      "2025-11-28 01:38:13 | INFO | Trainable parameters: 1,020,421\n",
      "INFO:speaker_profiling:Trainable parameters: 1,020,421\n",
      "2025-11-28 01:38:13 | INFO | Starting training...\n",
      "INFO:speaker_profiling:Starting training...\n",
      "2025-11-28 01:38:13 | INFO | Starting training...\n",
      "INFO:speaker_profiling:Starting training...\n",
      "{'loss': 3.9935, 'grad_norm': 2.6560184955596924, 'learning_rate': 0.0, 'epoch': 0.0}\n",
      "{'loss': 3.9935, 'grad_norm': 2.6560184955596924, 'learning_rate': 0.0, 'epoch': 0.0}\n",
      "{'loss': 4.0279, 'grad_norm': 3.0930967330932617, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.22}\n",
      "{'loss': 4.0279, 'grad_norm': 3.0930967330932617, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.22}\n",
      "{'loss': 4.0094, 'grad_norm': 2.8026723861694336, 'learning_rate': 1.1785714285714286e-05, 'epoch': 0.45}\n",
      "{'loss': 4.0094, 'grad_norm': 2.8026723861694336, 'learning_rate': 1.1785714285714286e-05, 'epoch': 0.45}\n",
      "{'loss': 3.9446, 'grad_norm': 4.1823015213012695, 'learning_rate': 1.773809523809524e-05, 'epoch': 0.67}\n",
      "{'loss': 3.9446, 'grad_norm': 4.1823015213012695, 'learning_rate': 1.773809523809524e-05, 'epoch': 0.67}\n",
      "{'loss': 3.9109, 'grad_norm': 3.6322474479675293, 'learning_rate': 2.369047619047619e-05, 'epoch': 0.89}\n",
      "{'loss': 3.9109, 'grad_norm': 3.6322474479675293, 'learning_rate': 2.369047619047619e-05, 'epoch': 0.89}\n",
      "  7%|██▋                                     | 221/3360 [00:07<01:25, 36.66it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|██████▋                                     | 5/33 [00:00<00:00, 47.49it/s]\u001b[A\n",
      " 15%|██████▋                                     | 5/33 [00:00<00:00, 47.49it/s]\u001b[A\n",
      " 30%|█████████████                              | 10/33 [00:00<00:00, 35.60it/s]\u001b[A\n",
      " 30%|█████████████                              | 10/33 [00:00<00:00, 35.60it/s]\u001b[A\n",
      " 42%|██████████████████▏                        | 14/33 [00:00<00:00, 34.09it/s]\u001b[A\n",
      " 42%|██████████████████▏                        | 14/33 [00:00<00:00, 34.09it/s]\u001b[A\n",
      " 58%|████████████████████████▊                  | 19/33 [00:00<00:00, 37.37it/s]\u001b[A\n",
      " 58%|████████████████████████▊                  | 19/33 [00:00<00:00, 37.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 23/33 [00:00<00:00, 33.56it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 23/33 [00:00<00:00, 33.56it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 27/33 [00:00<00:00, 32.85it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 27/33 [00:00<00:00, 32.85it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 31/33 [00:00<00:00, 34.13it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.7738170623779297, 'eval_gender_acc': 0.827016520894072, 'eval_gender_f1': 0.8230173942132638, 'eval_dialect_acc': 0.6034985422740525, 'eval_dialect_f1': 0.5825466898892336, 'eval_combined_f1': 0.7027820420512487, 'eval_runtime': 1.192, 'eval_samples_per_second': 863.259, 'eval_steps_per_second': 27.685, 'epoch': 1.0}\n",
      "  7%|██▋                                     | 224/3360 [00:09<01:25, 36.66it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.13it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.7738170623779297, 'eval_gender_acc': 0.827016520894072, 'eval_gender_f1': 0.8230173942132638, 'eval_dialect_acc': 0.6034985422740525, 'eval_dialect_f1': 0.5825466898892336, 'eval_combined_f1': 0.7027820420512487, 'eval_runtime': 1.192, 'eval_samples_per_second': 863.259, 'eval_steps_per_second': 27.685, 'epoch': 1.0}\n",
      "  7%|██▋                                     | 224/3360 [00:09<01:25, 36.66it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.13it/s]\u001b[A\n",
      "{'loss': 3.8299, 'grad_norm': 2.8989651203155518, 'learning_rate': 2.9523809523809526e-05, 'epoch': 1.12}\n",
      "{'loss': 3.8299, 'grad_norm': 2.8989651203155518, 'learning_rate': 2.9523809523809526e-05, 'epoch': 1.12}\n",
      "{'loss': 3.7288, 'grad_norm': 2.7272472381591797, 'learning_rate': 3.547619047619048e-05, 'epoch': 1.34}\n",
      "{'loss': 3.7288, 'grad_norm': 2.7272472381591797, 'learning_rate': 3.547619047619048e-05, 'epoch': 1.34}\n",
      "{'loss': 3.5891, 'grad_norm': 3.5174026489257812, 'learning_rate': 4.1428571428571437e-05, 'epoch': 1.56}\n",
      "{'loss': 3.5891, 'grad_norm': 3.5174026489257812, 'learning_rate': 4.1428571428571437e-05, 'epoch': 1.56}\n",
      "{'loss': 3.2558, 'grad_norm': 3.820382833480835, 'learning_rate': 4.738095238095238e-05, 'epoch': 1.79}\n",
      "{'loss': 3.2558, 'grad_norm': 3.820382833480835, 'learning_rate': 4.738095238095238e-05, 'epoch': 1.79}\n",
      " 13%|█████▎                                  | 448/3360 [00:16<01:31, 31.79it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 32.86it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 32.86it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 32.49it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 32.49it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 32.24it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 32.24it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 31.46it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 31.46it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.40it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.40it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 34.43it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 34.43it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 32.12it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 32.12it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.8839375972747803, 'eval_gender_acc': 0.9096209912536443, 'eval_gender_f1': 0.9094203138864021, 'eval_dialect_acc': 0.577259475218659, 'eval_dialect_f1': 0.5801299986730708, 'eval_combined_f1': 0.7447751562797364, 'eval_runtime': 1.2103, 'eval_samples_per_second': 850.182, 'eval_steps_per_second': 27.265, 'epoch': 2.0}\n",
      " 13%|█████▎                                  | 448/3360 [00:17<01:31, 31.79it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.8839375972747803, 'eval_gender_acc': 0.9096209912536443, 'eval_gender_f1': 0.9094203138864021, 'eval_dialect_acc': 0.577259475218659, 'eval_dialect_f1': 0.5801299986730708, 'eval_combined_f1': 0.7447751562797364, 'eval_runtime': 1.2103, 'eval_samples_per_second': 850.182, 'eval_steps_per_second': 27.265, 'epoch': 2.0}\n",
      " 13%|█████▎                                  | 448/3360 [00:17<01:31, 31.79it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.44it/s]\u001b[A\n",
      "{'loss': 2.8014, 'grad_norm': 5.99938440322876, 'learning_rate': 4.9540816326530614e-05, 'epoch': 2.01}\n",
      "{'loss': 2.8014, 'grad_norm': 5.99938440322876, 'learning_rate': 4.9540816326530614e-05, 'epoch': 2.01}\n",
      "{'loss': 2.5157, 'grad_norm': 4.307226657867432, 'learning_rate': 4.8690476190476194e-05, 'epoch': 2.23}\n",
      "{'loss': 2.5157, 'grad_norm': 4.307226657867432, 'learning_rate': 4.8690476190476194e-05, 'epoch': 2.23}\n",
      "{'loss': 2.35, 'grad_norm': 4.678863525390625, 'learning_rate': 4.784013605442177e-05, 'epoch': 2.46}\n",
      "{'loss': 2.35, 'grad_norm': 4.678863525390625, 'learning_rate': 4.784013605442177e-05, 'epoch': 2.46}\n",
      "{'loss': 2.2325, 'grad_norm': 6.0471673011779785, 'learning_rate': 4.698979591836735e-05, 'epoch': 2.68}\n",
      "{'loss': 2.2325, 'grad_norm': 6.0471673011779785, 'learning_rate': 4.698979591836735e-05, 'epoch': 2.68}\n",
      "{'loss': 2.1732, 'grad_norm': 4.597329616546631, 'learning_rate': 4.6139455782312926e-05, 'epoch': 2.9}\n",
      "{'loss': 2.1732, 'grad_norm': 4.597329616546631, 'learning_rate': 4.6139455782312926e-05, 'epoch': 2.9}\n",
      " 20%|████████                                | 672/3360 [00:24<01:23, 32.28it/s]\n",
      " 20%|████████                                | 672/3360 [00:24<01:23, 32.28it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|██████▋                                     | 5/33 [00:00<00:00, 40.17it/s]\u001b[A\n",
      " 15%|██████▋                                     | 5/33 [00:00<00:00, 40.17it/s]\u001b[A\n",
      " 30%|█████████████                              | 10/33 [00:00<00:00, 37.93it/s]\u001b[A\n",
      " 30%|█████████████                              | 10/33 [00:00<00:00, 37.93it/s]\u001b[A\n",
      " 42%|██████████████████▏                        | 14/33 [00:00<00:00, 37.35it/s]\u001b[A\n",
      " 42%|██████████████████▏                        | 14/33 [00:00<00:00, 37.35it/s]\u001b[A\n",
      " 55%|███████████████████████▍                   | 18/33 [00:00<00:00, 33.48it/s]\u001b[A\n",
      " 55%|███████████████████████▍                   | 18/33 [00:00<00:00, 33.48it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 22/33 [00:00<00:00, 34.93it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 22/33 [00:00<00:00, 34.93it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▉         | 26/33 [00:00<00:00, 34.28it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▉         | 26/33 [00:00<00:00, 34.28it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 30/33 [00:00<00:00, 34.97it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.327890157699585, 'eval_gender_acc': 0.9397473275024295, 'eval_gender_f1': 0.9395534228166141, 'eval_dialect_acc': 0.6763848396501457, 'eval_dialect_f1': 0.6831555498864025, 'eval_combined_f1': 0.8113544863515083, 'eval_runtime': 1.1608, 'eval_samples_per_second': 886.475, 'eval_steps_per_second': 28.429, 'epoch': 3.0}\n",
      " 20%|████████                                | 672/3360 [00:25<01:23, 32.28it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.97it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.327890157699585, 'eval_gender_acc': 0.9397473275024295, 'eval_gender_f1': 0.9395534228166141, 'eval_dialect_acc': 0.6763848396501457, 'eval_dialect_f1': 0.6831555498864025, 'eval_combined_f1': 0.8113544863515083, 'eval_runtime': 1.1608, 'eval_samples_per_second': 886.475, 'eval_steps_per_second': 28.429, 'epoch': 3.0}\n",
      " 20%|████████                                | 672/3360 [00:25<01:23, 32.28it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.97it/s]\u001b[A\n",
      "{'loss': 2.1443, 'grad_norm': 5.991999626159668, 'learning_rate': 4.5306122448979595e-05, 'epoch': 3.12}\n",
      "{'loss': 2.1443, 'grad_norm': 5.991999626159668, 'learning_rate': 4.5306122448979595e-05, 'epoch': 3.12}\n",
      "{'loss': 1.9476, 'grad_norm': 5.348849296569824, 'learning_rate': 4.445578231292517e-05, 'epoch': 3.35}\n",
      "{'loss': 1.9476, 'grad_norm': 5.348849296569824, 'learning_rate': 4.445578231292517e-05, 'epoch': 3.35}\n",
      "{'loss': 1.8594, 'grad_norm': 6.56632661819458, 'learning_rate': 4.360544217687075e-05, 'epoch': 3.57}\n",
      "{'loss': 1.8594, 'grad_norm': 6.56632661819458, 'learning_rate': 4.360544217687075e-05, 'epoch': 3.57}\n",
      "{'loss': 1.8671, 'grad_norm': 9.629389762878418, 'learning_rate': 4.275510204081633e-05, 'epoch': 3.79}\n",
      "{'loss': 1.8671, 'grad_norm': 9.629389762878418, 'learning_rate': 4.275510204081633e-05, 'epoch': 3.79}\n",
      " 27%|██████████▋                             | 894/3360 [00:32<01:05, 37.66it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 36.07it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 36.07it/s]\u001b[A\n",
      " 27%|████████████                                | 9/33 [00:00<00:00, 38.26it/s]\u001b[A\n",
      " 27%|████████████                                | 9/33 [00:00<00:00, 38.26it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 13/33 [00:00<00:00, 35.22it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 13/33 [00:00<00:00, 35.22it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 17/33 [00:00<00:00, 32.67it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 17/33 [00:00<00:00, 32.67it/s]\u001b[A\n",
      " 64%|███████████████████████████▎               | 21/33 [00:00<00:00, 33.12it/s]\u001b[A\n",
      " 64%|███████████████████████████▎               | 21/33 [00:00<00:00, 33.12it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 25/33 [00:00<00:00, 32.93it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 25/33 [00:00<00:00, 32.93it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 29/33 [00:00<00:00, 34.38it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 29/33 [00:00<00:00, 34.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.212411403656006, 'eval_gender_acc': 0.9494655004859086, 'eval_gender_f1': 0.9493177807372926, 'eval_dialect_acc': 0.6802721088435374, 'eval_dialect_f1': 0.6936481953438016, 'eval_combined_f1': 0.8214829880405471, 'eval_runtime': 1.1688, 'eval_samples_per_second': 880.418, 'eval_steps_per_second': 28.235, 'epoch': 4.0}\n",
      " 27%|██████████▋                             | 896/3360 [00:34<01:05, 37.66it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.93it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.212411403656006, 'eval_gender_acc': 0.9494655004859086, 'eval_gender_f1': 0.9493177807372926, 'eval_dialect_acc': 0.6802721088435374, 'eval_dialect_f1': 0.6936481953438016, 'eval_combined_f1': 0.8214829880405471, 'eval_runtime': 1.1688, 'eval_samples_per_second': 880.418, 'eval_steps_per_second': 28.235, 'epoch': 4.0}\n",
      " 27%|██████████▋                             | 896/3360 [00:34<01:05, 37.66it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.93it/s]\u001b[A\n",
      "{'loss': 1.7225, 'grad_norm': 5.847223281860352, 'learning_rate': 4.190476190476191e-05, 'epoch': 4.02}\n",
      "{'loss': 1.7225, 'grad_norm': 5.847223281860352, 'learning_rate': 4.190476190476191e-05, 'epoch': 4.02}\n",
      "{'loss': 1.7425, 'grad_norm': 10.233253479003906, 'learning_rate': 4.105442176870749e-05, 'epoch': 4.24}\n",
      "{'loss': 1.7425, 'grad_norm': 10.233253479003906, 'learning_rate': 4.105442176870749e-05, 'epoch': 4.24}\n",
      "{'loss': 1.6778, 'grad_norm': 4.198025703430176, 'learning_rate': 4.020408163265306e-05, 'epoch': 4.46}\n",
      "{'loss': 1.6778, 'grad_norm': 4.198025703430176, 'learning_rate': 4.020408163265306e-05, 'epoch': 4.46}\n",
      "{'loss': 1.661, 'grad_norm': 9.956928253173828, 'learning_rate': 3.935374149659864e-05, 'epoch': 4.69}\n",
      "{'loss': 1.661, 'grad_norm': 9.956928253173828, 'learning_rate': 3.935374149659864e-05, 'epoch': 4.69}\n",
      "{'loss': 1.5946, 'grad_norm': 9.01034927368164, 'learning_rate': 3.850340136054422e-05, 'epoch': 4.91}\n",
      "{'loss': 1.5946, 'grad_norm': 9.01034927368164, 'learning_rate': 3.850340136054422e-05, 'epoch': 4.91}\n",
      " 33%|█████████████                          | 1120/3360 [00:41<01:14, 30.22it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 35.59it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 35.59it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 37.92it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 37.92it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 35.90it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 35.90it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 33.94it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 33.94it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 34.06it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 34.06it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 35.83it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 35.83it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 35.42it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 35.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.1185288429260254, 'eval_gender_acc': 0.9543245869776482, 'eval_gender_f1': 0.9541976725107784, 'eval_dialect_acc': 0.7084548104956269, 'eval_dialect_f1': 0.7163218126127314, 'eval_combined_f1': 0.835259742561755, 'eval_runtime': 1.1302, 'eval_samples_per_second': 910.473, 'eval_steps_per_second': 29.199, 'epoch': 5.0}\n",
      " 33%|█████████████                          | 1120/3360 [00:42<01:14, 30.22it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 38.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.1185288429260254, 'eval_gender_acc': 0.9543245869776482, 'eval_gender_f1': 0.9541976725107784, 'eval_dialect_acc': 0.7084548104956269, 'eval_dialect_f1': 0.7163218126127314, 'eval_combined_f1': 0.835259742561755, 'eval_runtime': 1.1302, 'eval_samples_per_second': 910.473, 'eval_steps_per_second': 29.199, 'epoch': 5.0}\n",
      " 33%|█████████████                          | 1120/3360 [00:42<01:14, 30.22it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 38.60it/s]\u001b[A\n",
      "{'loss': 1.6248, 'grad_norm': 9.229698181152344, 'learning_rate': 3.76530612244898e-05, 'epoch': 5.13}\n",
      "{'loss': 1.6248, 'grad_norm': 9.229698181152344, 'learning_rate': 3.76530612244898e-05, 'epoch': 5.13}\n",
      "{'loss': 1.6014, 'grad_norm': 9.611603736877441, 'learning_rate': 3.680272108843538e-05, 'epoch': 5.36}\n",
      "{'loss': 1.6014, 'grad_norm': 9.611603736877441, 'learning_rate': 3.680272108843538e-05, 'epoch': 5.36}\n",
      "{'loss': 1.5709, 'grad_norm': 9.305719375610352, 'learning_rate': 3.595238095238095e-05, 'epoch': 5.58}\n",
      "{'loss': 1.5709, 'grad_norm': 9.305719375610352, 'learning_rate': 3.595238095238095e-05, 'epoch': 5.58}\n",
      "{'loss': 1.4616, 'grad_norm': 4.973947048187256, 'learning_rate': 3.510204081632653e-05, 'epoch': 5.8}\n",
      "{'loss': 1.4616, 'grad_norm': 4.973947048187256, 'learning_rate': 3.510204081632653e-05, 'epoch': 5.8}\n",
      " 40%|███████████████▌                       | 1342/3360 [00:49<00:52, 38.29it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 33.83it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 33.83it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 30.19it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 30.19it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 30.01it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 30.01it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 29.82it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 29.82it/s]\u001b[A\n",
      " 58%|████████████████████████▊                  | 19/33 [00:00<00:00, 28.37it/s]\u001b[A\n",
      " 58%|████████████████████████▊                  | 19/33 [00:00<00:00, 28.37it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 23/33 [00:00<00:00, 30.85it/s]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 23/33 [00:00<00:00, 30.85it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 27/33 [00:00<00:00, 32.57it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 27/33 [00:00<00:00, 32.57it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▋ | 32/33 [00:00<00:00, 37.20it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.090329885482788, 'eval_gender_acc': 0.9533527696793003, 'eval_gender_f1': 0.9531438583742813, 'eval_dialect_acc': 0.7240038872691934, 'eval_dialect_f1': 0.731250985099996, 'eval_combined_f1': 0.8421974217371386, 'eval_runtime': 1.2353, 'eval_samples_per_second': 833.028, 'eval_steps_per_second': 26.715, 'epoch': 6.0}\n",
      " 40%|███████████████▌                       | 1344/3360 [00:50<00:52, 38.29it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:01<00:00, 37.20it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.090329885482788, 'eval_gender_acc': 0.9533527696793003, 'eval_gender_f1': 0.9531438583742813, 'eval_dialect_acc': 0.7240038872691934, 'eval_dialect_f1': 0.731250985099996, 'eval_combined_f1': 0.8421974217371386, 'eval_runtime': 1.2353, 'eval_samples_per_second': 833.028, 'eval_steps_per_second': 26.715, 'epoch': 6.0}\n",
      " 40%|███████████████▌                       | 1344/3360 [00:50<00:52, 38.29it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:01<00:00, 37.20it/s]\u001b[A\n",
      "{'loss': 1.6452, 'grad_norm': 8.085410118103027, 'learning_rate': 3.4251700680272105e-05, 'epoch': 6.03}\n",
      "{'loss': 1.6452, 'grad_norm': 8.085410118103027, 'learning_rate': 3.4251700680272105e-05, 'epoch': 6.03}\n",
      "{'loss': 1.4751, 'grad_norm': 6.7359938621521, 'learning_rate': 3.340136054421769e-05, 'epoch': 6.25}\n",
      "{'loss': 1.4751, 'grad_norm': 6.7359938621521, 'learning_rate': 3.340136054421769e-05, 'epoch': 6.25}\n",
      "{'loss': 1.5318, 'grad_norm': 5.706206798553467, 'learning_rate': 3.255102040816327e-05, 'epoch': 6.47}\n",
      "{'loss': 1.5318, 'grad_norm': 5.706206798553467, 'learning_rate': 3.255102040816327e-05, 'epoch': 6.47}\n",
      "{'loss': 1.427, 'grad_norm': 12.007183074951172, 'learning_rate': 3.1700680272108845e-05, 'epoch': 6.7}\n",
      "{'loss': 1.427, 'grad_norm': 12.007183074951172, 'learning_rate': 3.1700680272108845e-05, 'epoch': 6.7}\n",
      "{'loss': 1.4356, 'grad_norm': 9.503003120422363, 'learning_rate': 3.0850340136054424e-05, 'epoch': 6.92}\n",
      "{'loss': 1.4356, 'grad_norm': 9.503003120422363, 'learning_rate': 3.0850340136054424e-05, 'epoch': 6.92}\n",
      " 47%|██████████████████▏                    | 1565/3360 [00:57<00:48, 37.13it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 33.02it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 33.02it/s]\u001b[A\n",
      " 27%|████████████                                | 9/33 [00:00<00:00, 38.62it/s]\u001b[A\n",
      " 27%|████████████                                | 9/33 [00:00<00:00, 38.62it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 13/33 [00:00<00:00, 34.14it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 13/33 [00:00<00:00, 34.14it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 17/33 [00:00<00:00, 34.92it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 17/33 [00:00<00:00, 34.92it/s]\u001b[A\n",
      " 64%|███████████████████████████▎               | 21/33 [00:00<00:00, 35.31it/s]\u001b[A\n",
      " 64%|███████████████████████████▎               | 21/33 [00:00<00:00, 35.31it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 25/33 [00:00<00:00, 34.63it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 25/33 [00:00<00:00, 34.63it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 29/33 [00:00<00:00, 34.48it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 29/33 [00:00<00:00, 34.48it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.10it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.9548168182373047, 'eval_gender_acc': 0.9582118561710399, 'eval_gender_f1': 0.958071083915375, 'eval_dialect_acc': 0.7395529640427599, 'eval_dialect_f1': 0.7464835805118525, 'eval_combined_f1': 0.8522773322136137, 'eval_runtime': 1.1667, 'eval_samples_per_second': 881.957, 'eval_steps_per_second': 28.284, 'epoch': 7.0}\n",
      " 47%|██████████████████▏                    | 1568/3360 [00:59<00:48, 37.13it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.10it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.9548168182373047, 'eval_gender_acc': 0.9582118561710399, 'eval_gender_f1': 0.958071083915375, 'eval_dialect_acc': 0.7395529640427599, 'eval_dialect_f1': 0.7464835805118525, 'eval_combined_f1': 0.8522773322136137, 'eval_runtime': 1.1667, 'eval_samples_per_second': 881.957, 'eval_steps_per_second': 28.284, 'epoch': 7.0}\n",
      " 47%|██████████████████▏                    | 1568/3360 [00:59<00:48, 37.13it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.10it/s]\u001b[A\n",
      "{'loss': 1.4464, 'grad_norm': 7.110738754272461, 'learning_rate': 3e-05, 'epoch': 7.14}\n",
      "{'loss': 1.4464, 'grad_norm': 7.110738754272461, 'learning_rate': 3e-05, 'epoch': 7.14}\n",
      "{'loss': 1.4144, 'grad_norm': 5.996765613555908, 'learning_rate': 2.9149659863945577e-05, 'epoch': 7.37}\n",
      "{'loss': 1.4144, 'grad_norm': 5.996765613555908, 'learning_rate': 2.9149659863945577e-05, 'epoch': 7.37}\n",
      "{'loss': 1.4045, 'grad_norm': 10.892069816589355, 'learning_rate': 2.829931972789116e-05, 'epoch': 7.59}\n",
      "{'loss': 1.4045, 'grad_norm': 10.892069816589355, 'learning_rate': 2.829931972789116e-05, 'epoch': 7.59}\n",
      "{'loss': 1.4378, 'grad_norm': 8.867630004882812, 'learning_rate': 2.7448979591836737e-05, 'epoch': 7.81}\n",
      "{'loss': 1.4378, 'grad_norm': 8.867630004882812, 'learning_rate': 2.7448979591836737e-05, 'epoch': 7.81}\n",
      " 53%|████████████████████▊                  | 1788/3360 [01:07<00:50, 31.02it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 35.24it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 35.24it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 37.77it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 37.77it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 35.02it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 35.02it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 34.02it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 34.02it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.89it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.89it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 33.33it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 33.33it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 33.35it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 33.35it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 33.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.9041962623596191, 'eval_gender_acc': 0.9591836734693877, 'eval_gender_f1': 0.9590643613647363, 'eval_dialect_acc': 0.7414965986394558, 'eval_dialect_f1': 0.7487056525108796, 'eval_combined_f1': 0.8538850069378079, 'eval_runtime': 1.1897, 'eval_samples_per_second': 864.921, 'eval_steps_per_second': 27.738, 'epoch': 8.0}\n",
      " 53%|████████████████████▊                  | 1792/3360 [01:08<00:50, 31.02it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 33.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.9041962623596191, 'eval_gender_acc': 0.9591836734693877, 'eval_gender_f1': 0.9590643613647363, 'eval_dialect_acc': 0.7414965986394558, 'eval_dialect_f1': 0.7487056525108796, 'eval_combined_f1': 0.8538850069378079, 'eval_runtime': 1.1897, 'eval_samples_per_second': 864.921, 'eval_steps_per_second': 27.738, 'epoch': 8.0}\n",
      " 53%|████████████████████▊                  | 1792/3360 [01:08<00:50, 31.02it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 33.78it/s]\u001b[A\n",
      "{'loss': 1.3883, 'grad_norm': 6.99690580368042, 'learning_rate': 2.6598639455782316e-05, 'epoch': 8.04}\n",
      "{'loss': 1.3883, 'grad_norm': 6.99690580368042, 'learning_rate': 2.6598639455782316e-05, 'epoch': 8.04}\n",
      "{'loss': 1.3773, 'grad_norm': 5.393935680389404, 'learning_rate': 2.5748299319727893e-05, 'epoch': 8.26}\n",
      "{'loss': 1.3773, 'grad_norm': 5.393935680389404, 'learning_rate': 2.5748299319727893e-05, 'epoch': 8.26}\n",
      "{'loss': 1.3738, 'grad_norm': 8.355711936950684, 'learning_rate': 2.489795918367347e-05, 'epoch': 8.48}\n",
      "{'loss': 1.3738, 'grad_norm': 8.355711936950684, 'learning_rate': 2.489795918367347e-05, 'epoch': 8.48}\n",
      "{'loss': 1.3709, 'grad_norm': 4.920288562774658, 'learning_rate': 2.404761904761905e-05, 'epoch': 8.71}\n",
      "{'loss': 1.3709, 'grad_norm': 4.920288562774658, 'learning_rate': 2.404761904761905e-05, 'epoch': 8.71}\n",
      "{'loss': 1.3762, 'grad_norm': 4.8043293952941895, 'learning_rate': 2.3197278911564625e-05, 'epoch': 8.93}\n",
      "{'loss': 1.3762, 'grad_norm': 4.8043293952941895, 'learning_rate': 2.3197278911564625e-05, 'epoch': 8.93}\n",
      " 60%|███████████████████████▎               | 2013/3360 [01:15<00:35, 37.97it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 37.49it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 35.73it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 35.35it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 35.73it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 35.35it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.49it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.49it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 34.75it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 34.75it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 34.41it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 34.41it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.18it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.8673062324523926, 'eval_gender_acc': 0.9552964042759962, 'eval_gender_f1': 0.9551250869784846, 'eval_dialect_acc': 0.7589893100097181, 'eval_dialect_f1': 0.7618028465427338, 'eval_combined_f1': 0.8584639667606092, 'eval_runtime': 1.1719, 'eval_samples_per_second': 878.048, 'eval_steps_per_second': 28.159, 'epoch': 9.0}\n",
      " 60%|███████████████████████▍               | 2016/3360 [01:16<00:35, 37.97it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.18it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.8673062324523926, 'eval_gender_acc': 0.9552964042759962, 'eval_gender_f1': 0.9551250869784846, 'eval_dialect_acc': 0.7589893100097181, 'eval_dialect_f1': 0.7618028465427338, 'eval_combined_f1': 0.8584639667606092, 'eval_runtime': 1.1719, 'eval_samples_per_second': 878.048, 'eval_steps_per_second': 28.159, 'epoch': 9.0}\n",
      " 60%|███████████████████████▍               | 2016/3360 [01:16<00:35, 37.97it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.18it/s]\u001b[A\n",
      "{'loss': 1.4317, 'grad_norm': 8.574822425842285, 'learning_rate': 2.2346938775510205e-05, 'epoch': 9.15}\n",
      "{'loss': 1.4317, 'grad_norm': 8.574822425842285, 'learning_rate': 2.2346938775510205e-05, 'epoch': 9.15}\n",
      "{'loss': 1.3641, 'grad_norm': 8.547947883605957, 'learning_rate': 2.1496598639455785e-05, 'epoch': 9.38}\n",
      "{'loss': 1.3641, 'grad_norm': 8.547947883605957, 'learning_rate': 2.1496598639455785e-05, 'epoch': 9.38}\n",
      "{'loss': 1.2886, 'grad_norm': 6.57733678817749, 'learning_rate': 2.064625850340136e-05, 'epoch': 9.6}\n",
      "{'loss': 1.2886, 'grad_norm': 6.57733678817749, 'learning_rate': 2.064625850340136e-05, 'epoch': 9.6}\n",
      "{'loss': 1.3484, 'grad_norm': 7.613359451293945, 'learning_rate': 1.9795918367346938e-05, 'epoch': 9.82}\n",
      "{'loss': 1.3484, 'grad_norm': 7.613359451293945, 'learning_rate': 1.9795918367346938e-05, 'epoch': 9.82}\n",
      " 67%|██████████████████████████             | 2240/3360 [01:23<00:35, 31.54it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 38.39it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 38.39it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 34.33it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 8/33 [00:00<00:00, 34.33it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 32.77it/s]\u001b[A\n",
      " 36%|███████████████▋                           | 12/33 [00:00<00:00, 32.77it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 32.80it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 16/33 [00:00<00:00, 32.80it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.76it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 20/33 [00:00<00:00, 33.76it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 34.96it/s]\u001b[A\n",
      " 73%|███████████████████████████████▎           | 24/33 [00:00<00:00, 34.96it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 33.85it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 28/33 [00:00<00:00, 33.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.026677131652832, 'eval_gender_acc': 0.9533527696793003, 'eval_gender_f1': 0.9531591189618547, 'eval_dialect_acc': 0.7444120505344995, 'eval_dialect_f1': 0.750765167577391, 'eval_combined_f1': 0.8519621432696228, 'eval_runtime': 1.175, 'eval_samples_per_second': 875.77, 'eval_steps_per_second': 28.086, 'epoch': 10.0}\n",
      " 67%|██████████████████████████             | 2240/3360 [01:25<00:35, 31.54it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.026677131652832, 'eval_gender_acc': 0.9533527696793003, 'eval_gender_f1': 0.9531591189618547, 'eval_dialect_acc': 0.7444120505344995, 'eval_dialect_f1': 0.750765167577391, 'eval_combined_f1': 0.8519621432696228, 'eval_runtime': 1.175, 'eval_samples_per_second': 875.77, 'eval_steps_per_second': 28.086, 'epoch': 10.0}\n",
      " 67%|██████████████████████████             | 2240/3360 [01:25<00:35, 31.54it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 35.55it/s]\u001b[A\n",
      "{'loss': 1.2366, 'grad_norm': 11.103212356567383, 'learning_rate': 1.8945578231292518e-05, 'epoch': 10.04}\n",
      "{'loss': 1.2366, 'grad_norm': 11.103212356567383, 'learning_rate': 1.8945578231292518e-05, 'epoch': 10.04}\n",
      "{'loss': 1.4022, 'grad_norm': 8.201406478881836, 'learning_rate': 1.8095238095238094e-05, 'epoch': 10.27}\n",
      "{'loss': 1.4022, 'grad_norm': 8.201406478881836, 'learning_rate': 1.8095238095238094e-05, 'epoch': 10.27}\n",
      "{'loss': 1.2872, 'grad_norm': 7.649861812591553, 'learning_rate': 1.7244897959183677e-05, 'epoch': 10.49}\n",
      "{'loss': 1.2872, 'grad_norm': 7.649861812591553, 'learning_rate': 1.7244897959183677e-05, 'epoch': 10.49}\n",
      "{'loss': 1.2955, 'grad_norm': 9.36719036102295, 'learning_rate': 1.6394557823129254e-05, 'epoch': 10.71}\n",
      "{'loss': 1.2955, 'grad_norm': 9.36719036102295, 'learning_rate': 1.6394557823129254e-05, 'epoch': 10.71}\n",
      "{'loss': 1.2986, 'grad_norm': 6.227913856506348, 'learning_rate': 1.554421768707483e-05, 'epoch': 10.94}\n",
      "{'loss': 1.2986, 'grad_norm': 6.227913856506348, 'learning_rate': 1.554421768707483e-05, 'epoch': 10.94}\n",
      " 73%|████████████████████████████▌          | 2464/3360 [01:32<00:28, 31.97it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|██████▋                                     | 5/33 [00:00<00:00, 42.77it/s]\u001b[A\n",
      " 15%|██████▋                                     | 5/33 [00:00<00:00, 42.77it/s]\u001b[A\n",
      " 30%|█████████████                              | 10/33 [00:00<00:00, 37.70it/s]\u001b[A\n",
      " 30%|█████████████                              | 10/33 [00:00<00:00, 37.70it/s]\u001b[A\n",
      " 42%|██████████████████▏                        | 14/33 [00:00<00:00, 34.54it/s]\u001b[A\n",
      " 42%|██████████████████▏                        | 14/33 [00:00<00:00, 34.54it/s]\u001b[A\n",
      " 55%|███████████████████████▍                   | 18/33 [00:00<00:00, 33.18it/s]\u001b[A\n",
      " 55%|███████████████████████▍                   | 18/33 [00:00<00:00, 33.18it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 22/33 [00:00<00:00, 33.37it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 22/33 [00:00<00:00, 33.37it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▉         | 26/33 [00:00<00:00, 31.89it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▉         | 26/33 [00:00<00:00, 31.89it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 30/33 [00:00<00:00, 32.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.9929322004318237, 'eval_gender_acc': 0.9601554907677357, 'eval_gender_f1': 0.9600447781477004, 'eval_dialect_acc': 0.7444120505344995, 'eval_dialect_f1': 0.7520414806045119, 'eval_combined_f1': 0.8560431293761062, 'eval_runtime': 1.2091, 'eval_samples_per_second': 851.038, 'eval_steps_per_second': 27.293, 'epoch': 11.0}\n",
      " 73%|████████████████████████████▌          | 2464/3360 [01:33<00:28, 31.97it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 32.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.9929322004318237, 'eval_gender_acc': 0.9601554907677357, 'eval_gender_f1': 0.9600447781477004, 'eval_dialect_acc': 0.7444120505344995, 'eval_dialect_f1': 0.7520414806045119, 'eval_combined_f1': 0.8560431293761062, 'eval_runtime': 1.2091, 'eval_samples_per_second': 851.038, 'eval_steps_per_second': 27.293, 'epoch': 11.0}\n",
      " 73%|████████████████████████████▌          | 2464/3360 [01:33<00:28, 31.97it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 32.60it/s]\u001b[A\n",
      "{'loss': 1.2514, 'grad_norm': 8.437828063964844, 'learning_rate': 1.469387755102041e-05, 'epoch': 11.16}\n",
      "{'loss': 1.2514, 'grad_norm': 8.437828063964844, 'learning_rate': 1.469387755102041e-05, 'epoch': 11.16}\n",
      "{'loss': 1.2901, 'grad_norm': 6.427807807922363, 'learning_rate': 1.3843537414965988e-05, 'epoch': 11.38}\n",
      "{'loss': 1.2901, 'grad_norm': 6.427807807922363, 'learning_rate': 1.3843537414965988e-05, 'epoch': 11.38}\n",
      "{'loss': 1.3258, 'grad_norm': 9.330254554748535, 'learning_rate': 1.2993197278911564e-05, 'epoch': 11.61}\n",
      "{'loss': 1.3258, 'grad_norm': 9.330254554748535, 'learning_rate': 1.2993197278911564e-05, 'epoch': 11.61}\n",
      "{'loss': 1.303, 'grad_norm': 6.564426422119141, 'learning_rate': 1.2142857142857144e-05, 'epoch': 11.83}\n",
      "{'loss': 1.303, 'grad_norm': 6.564426422119141, 'learning_rate': 1.2142857142857144e-05, 'epoch': 11.83}\n",
      " 80%|███████████████████████████████▏       | 2687/3360 [01:40<00:19, 35.41it/s]\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 31.92it/s]\u001b[A\n",
      " 12%|█████▎                                      | 4/33 [00:00<00:00, 31.92it/s]\u001b[A\n",
      " 27%|████████████                                | 9/33 [00:00<00:00, 38.35it/s]\u001b[A\n",
      " 27%|████████████                                | 9/33 [00:00<00:00, 38.35it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 13/33 [00:00<00:00, 35.07it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 13/33 [00:00<00:00, 35.07it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 17/33 [00:00<00:00, 32.93it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 17/33 [00:00<00:00, 32.93it/s]\u001b[A\n",
      " 64%|███████████████████████████▎               | 21/33 [00:00<00:00, 33.15it/s]\u001b[A\n",
      " 64%|███████████████████████████▎               | 21/33 [00:00<00:00, 33.15it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 25/33 [00:00<00:00, 32.88it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 25/33 [00:00<00:00, 32.88it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 29/33 [00:00<00:00, 34.02it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 29/33 [00:00<00:00, 34.02it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.8916064500808716, 'eval_gender_acc': 0.956268221574344, 'eval_gender_f1': 0.9561074740084665, 'eval_dialect_acc': 0.7541302235179786, 'eval_dialect_f1': 0.7604033529057668, 'eval_combined_f1': 0.8582554134571166, 'eval_runtime': 1.1823, 'eval_samples_per_second': 870.318, 'eval_steps_per_second': 27.911, 'epoch': 12.0}\n",
      " 80%|███████████████████████████████▏       | 2688/3360 [01:41<00:18, 35.41it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.35it/s]\u001b[A\n",
      "{'train_runtime': 101.8895, 'train_samples_per_second': 1050.697, 'train_steps_per_second': 32.977, 'train_loss': 1.91680788568088, 'epoch': 12.0}\n",
      " 80%|███████████████████████████████▏       | 2688/3360 [01:41<00:25, 26.38it/s]\n",
      "2025-11-28 01:39:55 | INFO | Saving model to /kaggle/working/output/best_model...\n",
      "INFO:speaker_profiling:Saving model to /kaggle/working/output/best_model...\n",
      "2025-11-28 01:39:55 | INFO | Training completed!\n",
      "INFO:speaker_profiling:Training completed!\n",
      "                                                                                \n",
      "\u001b[A{'eval_loss': 1.8916064500808716, 'eval_gender_acc': 0.956268221574344, 'eval_gender_f1': 0.9561074740084665, 'eval_dialect_acc': 0.7541302235179786, 'eval_dialect_f1': 0.7604033529057668, 'eval_combined_f1': 0.8582554134571166, 'eval_runtime': 1.1823, 'eval_samples_per_second': 870.318, 'eval_steps_per_second': 27.911, 'epoch': 12.0}\n",
      " 80%|███████████████████████████████▏       | 2688/3360 [01:41<00:18, 35.41it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:00<00:00, 34.35it/s]\u001b[A\n",
      "{'train_runtime': 101.8895, 'train_samples_per_second': 1050.697, 'train_steps_per_second': 32.977, 'train_loss': 1.91680788568088, 'epoch': 12.0}\n",
      " 80%|███████████████████████████████▏       | 2688/3360 [01:41<00:25, 26.38it/s]\n",
      "2025-11-28 01:39:55 | INFO | Saving model to /kaggle/working/output/best_model...\n",
      "INFO:speaker_profiling:Saving model to /kaggle/working/output/best_model...\n",
      "2025-11-28 01:39:55 | INFO | Training completed!\n",
      "INFO:speaker_profiling:Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "!python finetune.py --config configs/finetune.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /kaggle/working/output/best_model\n",
      "Files:\n",
      "  - training_args.bin (0.01 MB)\n",
      "  - model.safetensors (3.89 MB)\n"
     ]
    }
   ],
   "source": [
    "# Check saved model\n",
    "import os\n",
    "\n",
    "output_model_dir = \"/kaggle/working/output/best_model\"\n",
    "if os.path.exists(output_model_dir):\n",
    "    print(f\"Model saved at: {output_model_dir}\")\n",
    "    print(\"Files:\")\n",
    "    for f in os.listdir(output_model_dir):\n",
    "        size = os.path.getsize(os.path.join(output_model_dir, f)) / 1024 / 1024\n",
    "        print(f\"  - {f} ({size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"Model not found. Check training logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 01:40:08.889729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764294008.913982     535 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764294008.921047     535 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764294008.913982     535 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764294008.921047     535 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "2025-11-28 01:40:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:40:15 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:40:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:40:15 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:40:15 | INFO | Split: clean_test\n",
      "INFO:speaker_profiling:Split: clean_test\n",
      "2025-11-28 01:40:15 | INFO | Output: /kaggle/working/datasets/ViSpeech/clean_test\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/clean_test\n",
      "2025-11-28 01:40:15 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:40:15 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:40:15 | INFO | ViSpeech dataset - Split: clean_test\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: clean_test\n",
      "2025-11-28 01:40:15 | INFO |   Metadata: /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "2025-11-28 01:40:15 | INFO |   Audio dir: /kaggle/input/vispeech/clean_testset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/clean_testset\n",
      "2025-11-28 01:40:15 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:40:15 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:40:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:40:15 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:40:15 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:40:15 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:40:15 | INFO | Split: clean_test\n",
      "INFO:speaker_profiling:Split: clean_test\n",
      "2025-11-28 01:40:15 | INFO | Output: /kaggle/working/datasets/ViSpeech/clean_test\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/clean_test\n",
      "2025-11-28 01:40:15 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:40:15 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:40:15 | INFO | ViSpeech dataset - Split: clean_test\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: clean_test\n",
      "2025-11-28 01:40:15 | INFO |   Metadata: /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "2025-11-28 01:40:15 | INFO |   Audio dir: /kaggle/input/vispeech/clean_testset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/clean_testset\n",
      "2025-11-28 01:40:15 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:40:15 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:40:16 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:40:16 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:40:16 | INFO | Loaded 1500 total samples from /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "INFO:speaker_profiling:Loaded 1500 total samples from /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "2025-11-28 01:40:16 | INFO | Extracting features for 1500 samples...\n",
      "INFO:speaker_profiling:Extracting features for 1500 samples...\n",
      "Extracting features:   0%|                             | 0/1500 [00:00<?, ?it/s]2025-11-28 01:40:16 | INFO | Loaded 1500 total samples from /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "INFO:speaker_profiling:Loaded 1500 total samples from /kaggle/input/vispeech/metadata/clean_testset.csv\n",
      "2025-11-28 01:40:16 | INFO | Extracting features for 1500 samples...\n",
      "INFO:speaker_profiling:Extracting features for 1500 samples...\n",
      "Extracting features: 100%|██████████████████| 1500/1500 [01:11<00:00, 21.05it/s]\n",
      "2025-11-28 01:41:27 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/clean_test/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/clean_test/metadata.csv\n",
      "2025-11-28 01:41:27 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/clean_test/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/clean_test/stats.json\n",
      "2025-11-28 01:41:27 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:41:27 | INFO |   Success: 1500/1500\n",
      "INFO:speaker_profiling:  Success: 1500/1500\n",
      "2025-11-28 01:41:27 | INFO |   Failed: 0/1500\n",
      "INFO:speaker_profiling:  Failed: 0/1500\n",
      "2025-11-28 01:41:27 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:41:27 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:41:27 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:41:27 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:41:27 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:41:27 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/clean_test\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/clean_test\"  # for training set\n",
      "2025-11-28 01:41:27 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "Extracting features: 100%|██████████████████| 1500/1500 [01:11<00:00, 21.05it/s]\n",
      "2025-11-28 01:41:27 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/clean_test/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/clean_test/metadata.csv\n",
      "2025-11-28 01:41:27 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/clean_test/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/clean_test/stats.json\n",
      "2025-11-28 01:41:27 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:41:27 | INFO |   Success: 1500/1500\n",
      "INFO:speaker_profiling:  Success: 1500/1500\n",
      "2025-11-28 01:41:27 | INFO |   Failed: 0/1500\n",
      "INFO:speaker_profiling:  Failed: 0/1500\n",
      "2025-11-28 01:41:27 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:41:27 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:41:27 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:41:27 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:41:27 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:41:27 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/clean_test\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/clean_test\"  # for training set\n",
      "2025-11-28 01:41:27 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Extract test features (optional - if you want to evaluate)\n",
    "!python prepare_data.py \\\n",
    "    --dataset vispeech \\\n",
    "    --config configs/finetune.yaml \\\n",
    "    --output_dir /kaggle/working/datasets/ViSpeech/clean_test \\\n",
    "    --split clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 01:42:08.123574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764294128.148840     561 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764294128.156260     561 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764294128.148840     561 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764294128.156260     561 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "2025-11-28 01:42:14 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:42:14 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:42:14 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:42:14 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:42:14 | INFO | Split: noisy_test\n",
      "INFO:speaker_profiling:Split: noisy_test\n",
      "2025-11-28 01:42:14 | INFO | Output: /kaggle/working/datasets/ViSpeech/noisy_test\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/noisy_test\n",
      "2025-11-28 01:42:14 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:42:14 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:42:14 | INFO | ViSpeech dataset - Split: noisy_test\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: noisy_test\n",
      "2025-11-28 01:42:14 | INFO |   Metadata: /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "2025-11-28 01:42:14 | INFO |   Audio dir: /kaggle/input/vispeech/noisy_testset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/noisy_testset\n",
      "2025-11-28 01:42:14 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:42:14 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:42:14 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:42:14 | INFO | FEATURE EXTRACTION\n",
      "INFO:speaker_profiling:FEATURE EXTRACTION\n",
      "2025-11-28 01:42:14 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:42:14 | INFO | Dataset: vispeech\n",
      "INFO:speaker_profiling:Dataset: vispeech\n",
      "2025-11-28 01:42:14 | INFO | Split: noisy_test\n",
      "INFO:speaker_profiling:Split: noisy_test\n",
      "2025-11-28 01:42:14 | INFO | Output: /kaggle/working/datasets/ViSpeech/noisy_test\n",
      "INFO:speaker_profiling:Output: /kaggle/working/datasets/ViSpeech/noisy_test\n",
      "2025-11-28 01:42:14 | INFO | Model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:42:14 | INFO | ------------------------------------------------------------\n",
      "INFO:speaker_profiling:------------------------------------------------------------\n",
      "2025-11-28 01:42:14 | INFO | ViSpeech dataset - Split: noisy_test\n",
      "INFO:speaker_profiling:ViSpeech dataset - Split: noisy_test\n",
      "2025-11-28 01:42:14 | INFO |   Metadata: /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "INFO:speaker_profiling:  Metadata: /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "2025-11-28 01:42:14 | INFO |   Audio dir: /kaggle/input/vispeech/noisy_testset\n",
      "INFO:speaker_profiling:  Audio dir: /kaggle/input/vispeech/noisy_testset\n",
      "2025-11-28 01:42:14 | INFO | Loading WavLM model: microsoft/wavlm-base-plus\n",
      "INFO:speaker_profiling:Loading WavLM model: microsoft/wavlm-base-plus\n",
      "2025-11-28 01:42:14 | INFO | Device: cuda\n",
      "INFO:speaker_profiling:Device: cuda\n",
      "2025-11-28 01:42:15 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:42:15 | INFO | Loaded 1020 total samples from /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "INFO:speaker_profiling:Loaded 1020 total samples from /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "2025-11-28 01:42:15 | INFO | Extracting features for 1020 samples...\n",
      "INFO:speaker_profiling:Extracting features for 1020 samples...\n",
      "Extracting features:   0%|                             | 0/1020 [00:00<?, ?it/s]2025-11-28 01:42:15 | INFO | WavLM model loaded successfully\n",
      "INFO:speaker_profiling:WavLM model loaded successfully\n",
      "2025-11-28 01:42:15 | INFO | Loaded 1020 total samples from /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "INFO:speaker_profiling:Loaded 1020 total samples from /kaggle/input/vispeech/metadata/noisy_testset.csv\n",
      "2025-11-28 01:42:15 | INFO | Extracting features for 1020 samples...\n",
      "INFO:speaker_profiling:Extracting features for 1020 samples...\n",
      "Extracting features: 100%|██████████████████| 1020/1020 [00:46<00:00, 21.97it/s]\n",
      "Extracting features: 100%|██████████████████| 1020/1020 [00:46<00:00, 21.97it/s]\n",
      "2025-11-28 01:43:02 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/noisy_test/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/noisy_test/metadata.csv\n",
      "2025-11-28 01:43:02 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/noisy_test/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/noisy_test/stats.json\n",
      "2025-11-28 01:43:02 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:43:02 | INFO |   Success: 1020/1020\n",
      "INFO:speaker_profiling:  Success: 1020/1020\n",
      "2025-11-28 01:43:02 | INFO |   Failed: 0/1020\n",
      "INFO:speaker_profiling:  Failed: 0/1020\n",
      "2025-11-28 01:43:02 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:43:02 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:43:02 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:43:02 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:43:02 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:43:02 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/noisy_test\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/noisy_test\"  # for training set\n",
      "2025-11-28 01:43:02 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m2025-11-28 01:43:02 | INFO | Metadata saved to /kaggle/working/datasets/ViSpeech/noisy_test/metadata.csv\n",
      "INFO:speaker_profiling:Metadata saved to /kaggle/working/datasets/ViSpeech/noisy_test/metadata.csv\n",
      "2025-11-28 01:43:02 | INFO | Statistics saved to /kaggle/working/datasets/ViSpeech/noisy_test/stats.json\n",
      "INFO:speaker_profiling:Statistics saved to /kaggle/working/datasets/ViSpeech/noisy_test/stats.json\n",
      "2025-11-28 01:43:02 | INFO | Feature extraction completed:\n",
      "INFO:speaker_profiling:Feature extraction completed:\n",
      "2025-11-28 01:43:02 | INFO |   Success: 1020/1020\n",
      "INFO:speaker_profiling:  Success: 1020/1020\n",
      "2025-11-28 01:43:02 | INFO |   Failed: 0/1020\n",
      "INFO:speaker_profiling:  Failed: 0/1020\n",
      "2025-11-28 01:43:02 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:43:02 | INFO | Feature extraction completed!\n",
      "INFO:speaker_profiling:Feature extraction completed!\n",
      "2025-11-28 01:43:02 | INFO | ============================================================\n",
      "INFO:speaker_profiling:============================================================\n",
      "2025-11-28 01:43:02 | INFO | \n",
      "To use extracted features in training, update config:\n",
      "INFO:speaker_profiling:\n",
      "To use extracted features in training, update config:\n",
      "2025-11-28 01:43:02 | INFO |   data:\n",
      "INFO:speaker_profiling:  data:\n",
      "2025-11-28 01:43:02 | INFO |     train_dir: \"/kaggle/working/datasets/ViSpeech/noisy_test\"  # for training set\n",
      "INFO:speaker_profiling:    train_dir: \"/kaggle/working/datasets/ViSpeech/noisy_test\"  # for training set\n",
      "2025-11-28 01:43:02 | INFO |     val_dir: \"path/to/val/dir\"       # for validation set\n",
      "INFO:speaker_profiling:    val_dir: \"path/to/val/dir\"       # for validation set\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python prepare_data.py \\\n",
    "    --dataset vispeech \\\n",
    "    --config configs/finetune.yaml \\\n",
    "    --output_dir /kaggle/working/datasets/ViSpeech/noisy_test \\\n",
    "    --split noisy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUATION ON TEST SETS\n",
    "# ============================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/Profiling_gender_dialect')\n",
    "\n",
    "from src.models import ClassificationHeadModel\n",
    "\n",
    "# Dataset class for pre-extracted features\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.feature_dir = self.data_dir / 'features'\n",
    "        self.df = pd.read_csv(self.data_dir / 'metadata.csv')\n",
    "        print(f\"Loaded {len(self.df)} samples from {data_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        features = np.load(self.feature_dir / row['feature_name'])\n",
    "        return {\n",
    "            'input_features': torch.from_numpy(features).float(),\n",
    "            'gender_labels': torch.tensor(row['gender_label'], dtype=torch.long),\n",
    "            'dialect_labels': torch.tensor(row['dialect_label'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_gender_preds = []\n",
    "    all_dialect_preds = []\n",
    "    all_gender_labels = []\n",
    "    all_dialect_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features = batch['input_features'].to(device)\n",
    "            gender_labels = batch['gender_labels']\n",
    "            dialect_labels = batch['dialect_labels']\n",
    "            \n",
    "            outputs = model(input_features=features)\n",
    "            \n",
    "            gender_preds = outputs['gender_logits'].argmax(dim=-1).cpu().numpy()\n",
    "            dialect_preds = outputs['dialect_logits'].argmax(dim=-1).cpu().numpy()\n",
    "            \n",
    "            all_gender_preds.extend(gender_preds)\n",
    "            all_dialect_preds.extend(dialect_preds)\n",
    "            all_gender_labels.extend(gender_labels.numpy())\n",
    "            all_dialect_labels.extend(dialect_labels.numpy())\n",
    "    \n",
    "    return {\n",
    "        'gender_preds': np.array(all_gender_preds),\n",
    "        'dialect_preds': np.array(all_dialect_preds),\n",
    "        'gender_labels': np.array(all_gender_labels),\n",
    "        'dialect_labels': np.array(all_dialect_labels)\n",
    "    }\n",
    "\n",
    "def print_results(results, dataset_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTS ON {dataset_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    gender_acc = accuracy_score(results['gender_labels'], results['gender_preds']) * 100\n",
    "    gender_f1 = f1_score(results['gender_labels'], results['gender_preds'], average='weighted') * 100\n",
    "    dialect_acc = accuracy_score(results['dialect_labels'], results['dialect_preds']) * 100\n",
    "    dialect_f1 = f1_score(results['dialect_labels'], results['dialect_preds'], average='weighted') * 100\n",
    "    \n",
    "    print(f\"\\nGender  - Accuracy: {gender_acc:.2f}%  |  F1: {gender_f1:.2f}%\")\n",
    "    print(f\"Dialect - Accuracy: {dialect_acc:.2f}%  |  F1: {dialect_f1:.2f}%\")\n",
    "    \n",
    "    print(\"\\n--- Gender Classification Report ---\")\n",
    "    print(classification_report(results['gender_labels'], results['gender_preds'],\n",
    "                               target_names=['Male', 'Female'], digits=4))\n",
    "    \n",
    "    print(\"--- Dialect Classification Report ---\")\n",
    "    print(classification_report(results['dialect_labels'], results['dialect_preds'],\n",
    "                               target_names=['North', 'Central', 'South'], digits=4))\n",
    "    \n",
    "    print(\"Gender Confusion Matrix:\")\n",
    "    print(confusion_matrix(results['gender_labels'], results['gender_preds']))\n",
    "    \n",
    "    print(\"\\nDialect Confusion Matrix:\")\n",
    "    print(confusion_matrix(results['dialect_labels'], results['dialect_preds']))\n",
    "    \n",
    "    return {\n",
    "        'dataset': dataset_name,\n",
    "        'gender_acc': gender_acc,\n",
    "        'gender_f1': gender_f1,\n",
    "        'dialect_acc': dialect_acc,\n",
    "        'dialect_f1': dialect_f1\n",
    "    }\n",
    "\n",
    "print(\"Evaluation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load model weights\n",
    "model = ClassificationHeadModel(\n",
    "    hidden_size=768,\n",
    "    num_genders=2,\n",
    "    num_dialects=3,\n",
    "    dropout=0.1,\n",
    "    head_hidden_dim=256,\n",
    "    dialect_loss_weight=3.0\n",
    ")\n",
    "\n",
    "# Load best checkpoint\n",
    "checkpoint_dir = \"/kaggle/working/output/best_model\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    # Find the model file\n",
    "    model_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.bin') or f.endswith('.pt')]\n",
    "    if model_files:\n",
    "        model_path = os.path.join(checkpoint_dir, model_files[0])\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded model from: {model_path}\")\n",
    "    else:\n",
    "        # Try loading from pytorch_model.bin or model.safetensors\n",
    "        if os.path.exists(os.path.join(checkpoint_dir, 'pytorch_model.bin')):\n",
    "            state_dict = torch.load(os.path.join(checkpoint_dir, 'pytorch_model.bin'), map_location=device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(\"Loaded from pytorch_model.bin\")\n",
    "        elif os.path.exists(os.path.join(checkpoint_dir, 'model.safetensors')):\n",
    "            from safetensors.torch import load_file\n",
    "            state_dict = load_file(os.path.join(checkpoint_dir, 'model.safetensors'))\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(\"Loaded from model.safetensors\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_dir}\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded and ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Clean Test Set\n",
    "clean_test_dir = \"/kaggle/working/datasets/ViSpeech/clean_test\"\n",
    "\n",
    "if os.path.exists(clean_test_dir):\n",
    "    clean_dataset = FeatureDataset(clean_test_dir)\n",
    "    clean_loader = DataLoader(clean_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    clean_results = evaluate_model(model, clean_loader, device)\n",
    "    clean_metrics = print_results(clean_results, \"Clean Test Set\")\n",
    "else:\n",
    "    print(f\"Clean test features not found at {clean_test_dir}\")\n",
    "    print(\"Run the extract test features cell first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Noisy Test Set\n",
    "noisy_test_dir = \"/kaggle/working/datasets/ViSpeech/noisy_test\"\n",
    "\n",
    "if os.path.exists(noisy_test_dir):\n",
    "    noisy_dataset = FeatureDataset(noisy_test_dir)\n",
    "    noisy_loader = DataLoader(noisy_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    noisy_results = evaluate_model(model, noisy_loader, device)\n",
    "    noisy_metrics = print_results(noisy_results, \"Noisy Test Set\")\n",
    "else:\n",
    "    print(f\"Noisy test features not found at {noisy_test_dir}\")\n",
    "    print(\"Run the extract test features cell first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table - Compare with Baseline (PACLIC 2024 - ResNet34)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON WITH BASELINE (PACLIC 2024 - ResNet34)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Baseline results from PACLIC 2024\n",
    "baseline = {\n",
    "    'gender': {'clean': 95.35, 'noisy': 88.71},\n",
    "    'dialect': {'clean': 59.49, 'noisy': 45.67}\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "results_data = []\n",
    "\n",
    "if 'clean_metrics' in dir() and 'noisy_metrics' in dir():\n",
    "    for task in ['gender', 'dialect']:\n",
    "        for test_set in ['clean', 'noisy']:\n",
    "            baseline_val = baseline[task][test_set]\n",
    "            our_val = clean_metrics[f'{task}_acc'] if test_set == 'clean' else noisy_metrics[f'{task}_acc']\n",
    "            delta = our_val - baseline_val\n",
    "            delta_str = f\"+{delta:.2f}\" if delta > 0 else f\"{delta:.2f}\"\n",
    "            \n",
    "            results_data.append({\n",
    "                'Task': task.capitalize(),\n",
    "                'Test Set': test_set.capitalize(),\n",
    "                'Baseline (ResNet34)': f\"{baseline_val:.2f}%\",\n",
    "                'Our Model (WavLM)': f\"{our_val:.2f}%\",\n",
    "                'Delta': delta_str\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results_data)\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Clean Test - Gender: {clean_metrics['gender_acc']:.2f}% | Dialect: {clean_metrics['dialect_acc']:.2f}%\")\n",
    "    print(f\"Noisy Test - Gender: {noisy_metrics['gender_acc']:.2f}% | Dialect: {noisy_metrics['dialect_acc']:.2f}%\")\n",
    "else:\n",
    "    print(\"Run evaluation cells first!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8828507,
     "sourceId": 13858485,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
